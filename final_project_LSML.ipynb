{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dmwLGm98h9w"
   },
   "source": [
    "# Description of the dataset:\n",
    "\n",
    "\n",
    "This project is devoted to the question-answering task. You are going to work with the **BoolQ** dataset from SuperGLUE .\n",
    "\n",
    "BoolQ is a question answering dataset for yes/no.\n",
    "\n",
    "Each example is a triplet of (question, passage, answer), with the title of the page as optional additional context. I used two  `.jsonl` files (`train, val), where each line is a JSON dictionary with the following format:\n",
    "\n",
    "    Example:\n",
    "    \n",
    "    {\n",
    "      \"question\": \"is france the same timezone as the uk\",\n",
    "      \"passage\": \"At the Liberation of France in the summer of 1944, Metropolitan France kept GMT+2 as it was the time then used by the Allies (British Double Summer Time). In the winter of 1944--1945, Metropolitan France switched to GMT+1, same as in the United Kingdom, and switched again to GMT+2 in April 1945 like its British ally. In September 1945, Metropolitan France returned to GMT+1 (pre-war summer time), which the British had already done in July 1945. Metropolitan France was officially scheduled to return to GMT+0 on November 18, 1945 (the British returned to GMT+0 in on October 7, 1945), but the French government canceled the decision on November 5, 1945, and GMT+1 has since then remained the official time of Metropolitan France.\"\n",
    "      \"label\": false,\n",
    "      \"idx\": 123,\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPVnKXfBAfVT"
   },
   "source": [
    "## Data analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AolESpMeMVGZ",
    "outputId": "9b815bba-0faf-4939-b747-d0958ea40315"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\BCS.DESKTOP-\n",
      "[nltk_data]     732EA67\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\BCS.DESKTOP-\n",
      "[nltk_data]     732EA67\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "import os\n",
    "import random\n",
    "nltk.download('punkt')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import SVC\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\BCS.DESKTOP-732EA67\\\\My assignments Evgeniya\\\\LSML2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.dirname(os.path.abspath('train.jsonl'))\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "NxLUQXAgAfVU",
    "outputId": "5bfb6762-a95a-4f0b-a587-61f62127d550"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>passage</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>do iran and afghanistan speak the same language</td>\n",
       "      <td>Persian language -- Persian (/Ààp…úÀêr í…ôn, - É…ôn/)...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do good samaritan laws protect those who help ...</td>\n",
       "      <td>Good Samaritan law -- Good Samaritan laws offe...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is windows movie maker part of windows essentials</td>\n",
       "      <td>Windows Movie Maker -- Windows Movie Maker (fo...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is confectionary sugar the same as powdered sugar</td>\n",
       "      <td>Powdered sugar -- Powdered sugar, also called ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is elder scrolls online the same as skyrim</td>\n",
       "      <td>The Elder Scrolls Online -- As with other game...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "idx                                                      \n",
       "0      do iran and afghanistan speak the same language   \n",
       "1    do good samaritan laws protect those who help ...   \n",
       "2    is windows movie maker part of windows essentials   \n",
       "3    is confectionary sugar the same as powdered sugar   \n",
       "4           is elder scrolls online the same as skyrim   \n",
       "\n",
       "                                               passage  label  \n",
       "idx                                                            \n",
       "0    Persian language -- Persian (/Ààp…úÀêr í…ôn, - É…ôn/)...   True  \n",
       "1    Good Samaritan law -- Good Samaritan laws offe...   True  \n",
       "2    Windows Movie Maker -- Windows Movie Maker (fo...   True  \n",
       "3    Powdered sugar -- Powdered sugar, also called ...   True  \n",
       "4    The Elder Scrolls Online -- As with other game...  False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the dataset into a pandas dataframe.\n",
    "df_train = pd.read_csv(path+'\\\\train.jsonl', delimiter='\\t', header=None,names=['sentence_source'])\n",
    "\n",
    "\n",
    "database=[]\n",
    "for i in df_train.sentence_source:\n",
    "    i_json= json.loads(i)\n",
    "    i_list=[i_json['idx'],i_json['question'],i_json['passage'],i_json['label']]\n",
    "    database.append(i_list)\n",
    "\n",
    "df_train= pd.DataFrame(database,columns=['idx','question','passage','label']).set_index('idx')\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "Z150JetcSbAS",
    "outputId": "ab1d5a52-2b70-4853-a85d-67bab9215cc7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>passage</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>does ethanol take more energy make that produces</td>\n",
       "      <td>Ethanol fuel -- All biomass goes through at le...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is house tax and property tax are same</td>\n",
       "      <td>Property tax -- Property tax or 'house tax' is...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is pain experienced in a missing body part or ...</td>\n",
       "      <td>Phantom pain -- Phantom pain sensations are de...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is harry potter and the escape from gringotts ...</td>\n",
       "      <td>Harry Potter and the Escape from Gringotts -- ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is there a difference between hydroxyzine hcl ...</td>\n",
       "      <td>Hydroxyzine -- Hydroxyzine preparations requir...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "idx                                                      \n",
       "0     does ethanol take more energy make that produces   \n",
       "1               is house tax and property tax are same   \n",
       "2    is pain experienced in a missing body part or ...   \n",
       "3    is harry potter and the escape from gringotts ...   \n",
       "4    is there a difference between hydroxyzine hcl ...   \n",
       "\n",
       "                                               passage  label  \n",
       "idx                                                            \n",
       "0    Ethanol fuel -- All biomass goes through at le...  False  \n",
       "1    Property tax -- Property tax or 'house tax' is...   True  \n",
       "2    Phantom pain -- Phantom pain sensations are de...   True  \n",
       "3    Harry Potter and the Escape from Gringotts -- ...   True  \n",
       "4    Hydroxyzine -- Hydroxyzine preparations requir...   True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = pd.read_csv(path+\"\\\\val.jsonl\", delimiter='\\t', header=None, names=['sentence_source'])\n",
    "database=[]\n",
    "for i in df_val.sentence_source:\n",
    "    i_json= json.loads(i)\n",
    "    i_list=[i_json['idx'],i_json['question'],i_json['passage'],i_json['label']]\n",
    "    database.append(i_list)\n",
    "\n",
    "df_val= pd.DataFrame(database,columns=['idx','question','passage','label']).set_index('idx')\n",
    "df_val.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxvDK78QdMQq"
   },
   "source": [
    "I chose to use the Word2vec pre-trained model to vectorize words and then sentences.It's fast  and does ok on some simple (broadly-topical) tasks\n",
    "\n",
    "In this case, it is better not to delete stop words and punctuation , since the algorithm relies on the broader context of the sentence to obtain high-quality word vectors. In addition, we will get a result that can be compared with the results of Bert. Let's break down the Question column and Passage column  into words,clean any non-english words,stemms them and calculate some statistics. Stemming is needed when we use Wort2vec,because not all of the forms of words are presented in the Wort2vec dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tq-aZ6QlnHTq",
    "outputId": "e9cb59fe-2802-4755-a581-045c23239be5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do', 'iran', 'and', 'afghanistan', 'speak', 'the', 'same', 'languag']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "\n",
    "def words(i):\n",
    "   #clean the data from non-english words, tokenize it and stemms\n",
    "    regex = re.compile(\"[A-Za-z-]+\")\n",
    "    i= \" \".join(regex.findall(i))\n",
    "    tokens=word_tokenize(i.lower())\n",
    "    snowball = SnowballStemmer(\"english\")\n",
    "    tokens= [snowball.stem(j) for j in tokens ]\n",
    "    return tokens\n",
    "\n",
    "df_train['question_token']= df_train.question.apply(lambda x: words(x))\n",
    "df_train['passage_token']= df_train.passage.apply(lambda x: words(x))\n",
    "df_val['question_token']= df_val.question.apply(lambda x: words(x))\n",
    "df_val['passage_token']= df_val.passage.apply(lambda x: words(x))\n",
    "df_train['question_token'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1_ijAigjPdXk",
    "outputId": "0c4658c8-afd9-47e4-b910-8f254e34d624"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the number of missing values : \n",
      "Number of missing values  in Question column: 0\n",
      "Number of missing values  in Passage column: 0\n",
      "Number of missing values  in Label column: 0\n",
      "\n",
      "Number of examples in dataset: 9427\n",
      "\n",
      "Class_distribution: True     5874\n",
      "False    3553\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Mean sentence length of a passage: 96.0\n",
      "Mean length of a question: 9.0\n",
      "\n",
      "Number of unique words : 32137\n"
     ]
    }
   ],
   "source": [
    "\n",
    "example_number = df_train.shape[0]\n",
    "class_distribution =  df_train.label.value_counts()\n",
    "\n",
    "mean_sentence_length_for_passage=[]\n",
    "for i in df_train.passage_token:\n",
    "    mean_sentence_length_for_passage.append(len(i))\n",
    "mean_sentence_length_for_passage=np.mean(mean_sentence_length_for_passage)\n",
    "\n",
    "mean_sentence_length_for_question=[]\n",
    "for i in df_train.question_token:\n",
    "    mean_sentence_length_for_question.append(len(i))\n",
    "mean_sentence_length_for_question=np.mean(mean_sentence_length_for_question)\n",
    "\n",
    "number_unique_words=set()\n",
    "for i in df_train['question_token']:\n",
    "    for j in i:\n",
    "        number_unique_words.add(j)\n",
    "for i in df_train['passage_token']:\n",
    "    for j in i:\n",
    "         number_unique_words.add(j)\n",
    "number_unique_words=len(number_unique_words)\n",
    "\n",
    "\n",
    "\n",
    "print('Checking the number of missing values : ' )\n",
    "print(f'Number of missing values  in Question column: {df_train.question.isnull().sum()}',f'Number of missing values  in Passage column: {df_train.passage.isnull().sum()}',f'Number of missing values  in Label column: {df_train.label.isnull().sum()}','',sep='\\n')\n",
    "print(f'Number of examples in dataset: {example_number}','',sep='\\n' )\n",
    "print(f'Class_distribution: {class_distribution}','',sep='\\n' )\n",
    "\n",
    "print(f'Mean sentence length of a passage: {round(mean_sentence_length_for_passage,0)}',f'Mean length of a question: {round(mean_sentence_length_for_question,0)}','',sep='\\n')\n",
    "\n",
    "print(f'Number of unique words : {number_unique_words}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7BqlLDi90fPc"
   },
   "source": [
    "As we can see, we don't have missing values in our dataset . But the dataset is unbalanced. The number of \"true\" answers is 1.6 times more than the number of \"false\" answers\n",
    "\n",
    " There's no single, official way to use word2vec to represent sentences. Once quick & crude approach is to create a vector for a sentence  by averaging all the word-vectors together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WAdbEyLRoqzl",
    "outputId": "214497fa-cc58-4529-99d8-fb1952765786"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "# taking embeddings of the words from word2vec\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "\n",
    "word2vec = gensim.downloader.load('word2vec-google-news-300')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "lwiLdPIXzcFN",
    "outputId": "cfe6b3e6-8aff-4045-88c1-01ff94af0a8f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>passage</th>\n",
       "      <th>label</th>\n",
       "      <th>question_token</th>\n",
       "      <th>passage_token</th>\n",
       "      <th>question_w2v_emb</th>\n",
       "      <th>passage_w2v_emb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>do iran and afghanistan speak the same language</td>\n",
       "      <td>Persian language -- Persian (/Ààp…úÀêr í…ôn, - É…ôn/)...</td>\n",
       "      <td>True</td>\n",
       "      <td>[do, iran, and, afghanistan, speak, the, same,...</td>\n",
       "      <td>[persian, languag, --, persian, p, r, n, -, n,...</td>\n",
       "      <td>[0.021993002, 0.015218099, 0.12709554, 0.23776...</td>\n",
       "      <td>[-0.0054717134, 0.03689535, 0.08077174, 0.1108...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do good samaritan laws protect those who help ...</td>\n",
       "      <td>Good Samaritan law -- Good Samaritan laws offe...</td>\n",
       "      <td>True</td>\n",
       "      <td>[do, good, samaritan, law, protect, those, who...</td>\n",
       "      <td>[good, samaritan, law, --, good, samaritan, la...</td>\n",
       "      <td>[0.035839844, 0.041729737, 0.02211914, 0.09774...</td>\n",
       "      <td>[-0.0034797825, 0.019353127, 0.029191853, 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is windows movie maker part of windows essentials</td>\n",
       "      <td>Windows Movie Maker -- Windows Movie Maker (fo...</td>\n",
       "      <td>True</td>\n",
       "      <td>[is, window, movi, maker, part, of, window, es...</td>\n",
       "      <td>[window, movi, maker, --, window, movi, maker,...</td>\n",
       "      <td>[0.05419922, 0.017130533, 0.015370687, 0.03619...</td>\n",
       "      <td>[-0.015647124, 0.011743498, -0.022090148, 0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is confectionary sugar the same as powdered sugar</td>\n",
       "      <td>Powdered sugar -- Powdered sugar, also called ...</td>\n",
       "      <td>True</td>\n",
       "      <td>[is, confectionari, sugar, the, same, as, powd...</td>\n",
       "      <td>[powder, sugar, --, powder, sugar, also, call,...</td>\n",
       "      <td>[-0.023633685, -0.054600306, 0.0531529, 0.0678...</td>\n",
       "      <td>[-0.009095291, -0.032276616, 0.035875518, 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is elder scrolls online the same as skyrim</td>\n",
       "      <td>The Elder Scrolls Online -- As with other game...</td>\n",
       "      <td>False</td>\n",
       "      <td>[is, elder, scroll, onlin, the, same, as, skyrim]</td>\n",
       "      <td>[the, elder, scroll, onlin, --, as, with, othe...</td>\n",
       "      <td>[0.06457084, 0.031964984, -0.006452288, 0.0318...</td>\n",
       "      <td>[0.061226837, 0.04547988, 0.04089217, 0.051684...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "idx                                                      \n",
       "0      do iran and afghanistan speak the same language   \n",
       "1    do good samaritan laws protect those who help ...   \n",
       "2    is windows movie maker part of windows essentials   \n",
       "3    is confectionary sugar the same as powdered sugar   \n",
       "4           is elder scrolls online the same as skyrim   \n",
       "\n",
       "                                               passage  label  \\\n",
       "idx                                                             \n",
       "0    Persian language -- Persian (/Ààp…úÀêr í…ôn, - É…ôn/)...   True   \n",
       "1    Good Samaritan law -- Good Samaritan laws offe...   True   \n",
       "2    Windows Movie Maker -- Windows Movie Maker (fo...   True   \n",
       "3    Powdered sugar -- Powdered sugar, also called ...   True   \n",
       "4    The Elder Scrolls Online -- As with other game...  False   \n",
       "\n",
       "                                        question_token  \\\n",
       "idx                                                      \n",
       "0    [do, iran, and, afghanistan, speak, the, same,...   \n",
       "1    [do, good, samaritan, law, protect, those, who...   \n",
       "2    [is, window, movi, maker, part, of, window, es...   \n",
       "3    [is, confectionari, sugar, the, same, as, powd...   \n",
       "4    [is, elder, scroll, onlin, the, same, as, skyrim]   \n",
       "\n",
       "                                         passage_token  \\\n",
       "idx                                                      \n",
       "0    [persian, languag, --, persian, p, r, n, -, n,...   \n",
       "1    [good, samaritan, law, --, good, samaritan, la...   \n",
       "2    [window, movi, maker, --, window, movi, maker,...   \n",
       "3    [powder, sugar, --, powder, sugar, also, call,...   \n",
       "4    [the, elder, scroll, onlin, --, as, with, othe...   \n",
       "\n",
       "                                      question_w2v_emb  \\\n",
       "idx                                                      \n",
       "0    [0.021993002, 0.015218099, 0.12709554, 0.23776...   \n",
       "1    [0.035839844, 0.041729737, 0.02211914, 0.09774...   \n",
       "2    [0.05419922, 0.017130533, 0.015370687, 0.03619...   \n",
       "3    [-0.023633685, -0.054600306, 0.0531529, 0.0678...   \n",
       "4    [0.06457084, 0.031964984, -0.006452288, 0.0318...   \n",
       "\n",
       "                                       passage_w2v_emb  \n",
       "idx                                                     \n",
       "0    [-0.0054717134, 0.03689535, 0.08077174, 0.1108...  \n",
       "1    [-0.0034797825, 0.019353127, 0.029191853, 0.08...  \n",
       "2    [-0.015647124, 0.011743498, -0.022090148, 0.07...  \n",
       "3    [-0.009095291, -0.032276616, 0.035875518, 0.08...  \n",
       "4    [0.061226837, 0.04547988, 0.04089217, 0.051684...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_embeddings_sentence_w2v(sentence,model):\n",
    "    return np.mean([model.get_vector(word) for word in sentence if word in model], axis=0)\n",
    "\n",
    "df_train['question_w2v_emb']=df_train.question_token.apply(lambda x: get_embeddings_sentence_w2v(x,word2vec))\n",
    "df_train['passage_w2v_emb']=df_train.passage_token.apply(lambda x: get_embeddings_sentence_w2v(x,word2vec))\n",
    "df_val['question_w2v_emb']=df_val.question_token.apply(lambda x: get_embeddings_sentence_w2v(x,word2vec))\n",
    "df_val['passage_w2v_emb']=df_val.passage_token.apply(lambda x: get_embeddings_sentence_w2v(x,word2vec))\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNJE64Gr9xYf"
   },
   "source": [
    "There are many stratages to train the model . I choose to concatinate question and passage texts and give it as an input to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CVI67ekfxfa3"
   },
   "outputs": [],
   "source": [
    "def X_creation(dataset):\n",
    "    X_dataset=[]\n",
    "    for i in range(dataset.shape[0]):\n",
    "          concatinated_line = dataset['question_w2v_emb'][i].tolist()+dataset['passage_w2v_emb'][i].tolist()\n",
    "          X_dataset.append(concatinated_line)\n",
    "    return X_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IiWBXKfD6RGG",
    "outputId": "f6c0c642-17c6-4e8f-f3a3-5e73bd24e64c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train= X_creation(df_train)\n",
    "y_train=df_train['label']\n",
    "X_test= X_creation(df_val)\n",
    "y_test=df_val['label']\n",
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhMjh1ot5eDF"
   },
   "source": [
    "Let's take SVM as a classification model . But before training  the model let's handle with class imbalance with the help of ADASYN. ADASYN is an oversampling method that generates synthetic samples for minority classes, balancing the dataset and improving classification accuracy.As a performance metric let's choose accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkDuqStI_7Vc"
   },
   "source": [
    "## Create and run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ICv7jnDyA0z7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cRA2KuWgCsQd"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iIyMVJyqF_DN",
    "outputId": "139d8e77-298d-4576-b46c-bdea9abab0f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting MLproject\n"
     ]
    }
   ],
   "source": [
    "%%writefile MLproject\n",
    "name: tutorial\n",
    "\n",
    "conda_env: conda.yaml\n",
    "\n",
    "entry_points:\n",
    "  main:\n",
    "    parameters:\n",
    "      C: float\n",
    "    command: \"python train.py {C}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j25D3GCTJFyf",
    "outputId": "152331b6-02bf-4523-d99c-5f1d50a82bf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting conda.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile conda.yaml\n",
    "name: tutorial\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - numpy>=1.14.3\n",
    "  - pandas>=1.0.0\n",
    "  - scikit-learn=0.19.1\n",
    "  - pip\n",
    "  - pip:\n",
    "    - mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 862
    },
    "id": "4xt-1aNxAnJb",
    "outputId": "b803a93f-a187-44f1-b954-7d9be51723dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with ADASYN (C=0.100000):\n",
      "  Accuracy: 0.6217125382262997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/18 21:54:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run treasured-dove-995 at: http://127.0.0.1:5000/#/experiments/1/runs/f61d24d1b9344e9a998f2a2f03e82389\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/1\n",
      "SVM with ADASYN (C=1.000000):\n",
      "  Accuracy: 0.653822629969419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/18 21:55:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run dapper-whale-878 at: http://127.0.0.1:5000/#/experiments/1/runs/36d6aed1ec044a8db6c1feee5227a7dd\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/1\n",
      "SVM with ADASYN (C=5.000000):\n",
      "  Accuracy: 0.6724770642201835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/18 21:56:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run invincible-newt-149 at: http://127.0.0.1:5000/#/experiments/1/runs/8d7bcce8539e468e96622b24402fe0ac\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/1\n",
      "SVM with ADASYN (C=10.000000):\n",
      "  Accuracy: 0.6730886850152905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/18 21:58:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run charming-grub-730 at: http://127.0.0.1:5000/#/experiments/1/runs/6502cfb885d04cdabc769735bbab9616\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/1\n",
      "SVM with ADASYN (C=20.000000):\n",
      "  Accuracy: 0.6770642201834862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/18 22:01:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run inquisitive-mink-862 at: http://127.0.0.1:5000/#/experiments/1/runs/1ccfafbe7c4c4670be48e098135bc792\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "MLFLOW_SERVER_URL = 'http://127.0.0.1:5000/'\n",
    "experiment_name = 'experiment-for-svm'\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(40)\n",
    "\n",
    "\n",
    "client = mlflow.tracking.MlflowClient(MLFLOW_SERVER_URL)\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_SERVER_URL)\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "\n",
    "for C in ((0.1), (1.0), (5.0), (10),(20)):\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        adsin=ADASYN(sampling_strategy=0.8, n_neighbors=5, random_state=13)\n",
    "        X_resampled_train,y_resampled_train = adsin.fit_resample(X_train,y_train )\n",
    "\n",
    "        SVM=SVC(C=C, kernel='rbf', degree=3, gamma='scale', decision_function_shape='ovr', random_state=42)\n",
    "        SVM.fit(X_resampled_train,y_resampled_train)\n",
    "        y_pred=SVM.predict(X_test)\n",
    "\n",
    "        quality= accuracy_score(y_test, y_pred)\n",
    "\n",
    "        print(\"SVM with ADASYN (C=%f):\" % (C))\n",
    "        print(\"  Accuracy: %s\" % quality)\n",
    "\n",
    "        mlflow.log_param(\"C\", C)\n",
    "        mlflow.log_metric(\"Accuracy\", quality)\n",
    "\n",
    "        mlflow.sklearn.log_model(SVM, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_registered_model(\"svm-learn-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Run: data=<RunData: metrics={'Accuracy': 0.6770642201834862}, params={'C': '20'}, tags={'mlflow.log-model.history': '[{\"run_id\": \"1ccfafbe7c4c4670be48e098135bc792\", '\n",
       "                             '\"artifact_path\": \"model\", \"utc_time_created\": '\n",
       "                             '\"2024-12-18 19:01:11.310054\", \"model_uuid\": '\n",
       "                             '\"fabeef7b16ca4d94b0fd16c03c02635e\", \"flavors\": '\n",
       "                             '{\"python_function\": {\"model_path\": \"model.pkl\", '\n",
       "                             '\"predict_fn\": \"predict\", \"loader_module\": '\n",
       "                             '\"mlflow.sklearn\", \"python_version\": \"3.10.9\", '\n",
       "                             '\"env\": {\"conda\": \"conda.yaml\", \"virtualenv\": '\n",
       "                             '\"python_env.yaml\"}}, \"sklearn\": '\n",
       "                             '{\"pickled_model\": \"model.pkl\", '\n",
       "                             '\"sklearn_version\": \"1.2.1\", '\n",
       "                             '\"serialization_format\": \"cloudpickle\", \"code\": '\n",
       "                             'null}}}]',\n",
       " 'mlflow.runName': 'inquisitive-mink-862',\n",
       " 'mlflow.source.name': 'C:\\\\Users\\\\BCS.DESKTOP-732EA67\\\\Python3.n\\\\lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
       " 'mlflow.source.type': 'LOCAL',\n",
       " 'mlflow.user': 'BCS'}>, info=<RunInfo: artifact_uri='file:///C:/Users/BCS.DESKTOP-732EA67/artifacts/1/1ccfafbe7c4c4670be48e098135bc792/artifacts', end_time=1734548477217, experiment_id='1', lifecycle_stage='active', run_id='1ccfafbe7c4c4670be48e098135bc792', run_name='inquisitive-mink-862', run_uuid='1ccfafbe7c4c4670be48e098135bc792', start_time=1734548332945, status='FINISHED', user_id='BCS'>, inputs=<RunInputs: dataset_inputs=[]>>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = mlflow.tracking.MlflowClient(MLFLOW_SERVER_URL)\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "client.search_runs(experiment.experiment_id)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "F5mwEFW9aqQF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking how the model works in test environment\n",
    "reg_model_name = \"svm-learn-model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/18 22:18:25 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: svm-learn-model, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6770642201834862\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# register model\n",
    "client.create_registered_model(reg_model_name)\n",
    "# create a new version\n",
    "result = client.create_model_version(\n",
    "name=reg_model_name,\n",
    "source=\"file:///C:/Users/BCS.DESKTOP-732EA67/artifacts/1/1ccfafbe7c4c4670be48e098135bc792/artifacts/model\",\n",
    "run_id='1ccfafbe7c4c4670be48e098135bc792'\n",
    ")\n",
    "\n",
    "\n",
    "client.transition_model_version_stage(\n",
    "name=reg_model_name,\n",
    "version=result.version,\n",
    "stage=\"Staging\"\n",
    ")\n",
    "\n",
    "\n",
    "model = mlflow.sklearn.load_model(model_uri=f\"models:/{reg_model_name}/Staging\")\n",
    "y_pred = model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "8n5_FJS2do-U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6770642201834862\n"
     ]
    }
   ],
   "source": [
    "# checking how the model works in production environment\n",
    "client.transition_model_version_stage(\n",
    "name=reg_model_name,\n",
    "version=result.version,\n",
    "stage=\"Production\"\n",
    "  )\n",
    "\n",
    "model = mlflow.sklearn.load_model(model_uri=f\"models:/{reg_model_name}/Production\")\n",
    "y_pred = model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GL0wYx4Y2-O"
   },
   "source": [
    "## Python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nhha0H1756mV",
    "outputId": "b4bcd4f9-edd5-4e8c-ca3e-d86fb358c58e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6770642201834862\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "adsin=ADASYN(sampling_strategy=0.8, n_neighbors=5, random_state=13)\n",
    "X_resampled_train,y_resampled_train = adsin.fit_resample(X_train,y_train )\n",
    "\n",
    "SVM=SVC(C=20, kernel='rbf', degree=3, gamma='scale', decision_function_shape='ovr', random_state=42)\n",
    "SVM.fit(X_resampled_train,y_resampled_train)\n",
    "y_pred=SVM.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fi3kqXc2YvCU"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "NL6AkMjaS_Rc"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "raw_data = pickle.dumps(SVM)\n",
    "\n",
    "with open('SVM.pickle', 'wb') as f:\n",
    "    f.write(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xFoSj48S-KA7",
    "outputId": "fb1e5c54-2cce-4eb0-c7e3-10bc08309531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile server.py\n",
    "from flask import Flask, request\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "def load_model(pickle_path):\n",
    "    with open(pickle_path, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "        model = pickle.loads(raw_data)\n",
    "    return model\n",
    "\n",
    "model = load_model('SVM.pickle')\n",
    "\n",
    "def predict_result(data_list):\n",
    "    result = SVM.predict(data_list)\n",
    "    return result\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def hello():\n",
    "    return \"Hello, from Flask\"\n",
    "\n",
    "@app.route('/predict', methods=[\"GET\", \"POST\"])\n",
    "def predict_q():\n",
    "    if request.method == \"POST\":\n",
    "        data = request.get_json(force=True)\n",
    "        data_list = data['data_list']\n",
    "\n",
    "        result = predict_result(data_list)\n",
    "\n",
    "        response = {\n",
    "            \"result\": result\n",
    "        }\n",
    "        return response\n",
    "    else:\n",
    "        return \"You should use only POST query\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(\"127.0.0.1\", 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "kl4nLFnPS2XD"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "data = {\n",
    "    'data_list': X_test[:5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "nd5aH-SuZQAL",
    "outputId": "6d2eef0d-921f-4d40-9db3-c6a69d9b536b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You should use only POST query\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(\"http://127.0.0.1:8000/predict\", json=data)\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, from Flask\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(\"http://127.0.0.1:8000/\", json=data)\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [500]>\n"
     ]
    }
   ],
   "source": [
    "r = requests.post(\"http://127.0.0.1:8000/predict\", json=data)\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
